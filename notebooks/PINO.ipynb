{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd21fb0-1b84-4c63-8668-5104643fc8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator_aliasing.data.utils import get_data\n",
    "from operator_aliasing.models.utils import get_model\n",
    "from operator_aliasing.train.utils import get_loss\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51eb9af-2432-42a2-82d1-60ed8cec836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test db for resolution 16 with 100 samples \n",
      "Loading test db for resolution 16 with 100 samples \n"
     ]
    }
   ],
   "source": [
    "# Get Data\n",
    "data_kwargs = {\n",
    "    'dataset_name': 'darcy',\n",
    "    'filter_lim': 3,\n",
    "    'img_size': 16,\n",
    "    'downsample_dim': -1,\n",
    "    'train': True,\n",
    "    'batch_size':16,\n",
    "    'seed':0,\n",
    "}\n",
    "\n",
    "train_dataloader, test_loaders = get_data(**data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0744d812-6977-43f7-835a-364c4a7783f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "            model_name='FNO2D',\n",
    "            out_channels=1,\n",
    "            in_channels=1,\n",
    "            hidden_channels=32,\n",
    "            max_modes=16,\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90f4a67-56bd-45c8-8d7b-11671d68a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    '''\n",
    "    loss function with rel/abs Lp loss\n",
    "    '''\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "# PINNs Loss\n",
    "\n",
    "# u = model pred\n",
    "# a = label\n",
    "def FDM_Darcy(u, a, D=1):\n",
    "    batchsize = u.size(0)\n",
    "    size = u.size(1)\n",
    "    u = u.reshape(batchsize, size, size)\n",
    "    a = a.reshape(batchsize, size, size)\n",
    "    dx = D / (size - 1)\n",
    "    dy = dx\n",
    "\n",
    "    # ux: (batch, size-2, size-2)\n",
    "    ux = (u[:, 2:, 1:-1] - u[:, :-2, 1:-1]) / (2 * dx)\n",
    "    uy = (u[:, 1:-1, 2:] - u[:, 1:-1, :-2]) / (2 * dy)\n",
    "\n",
    "    # ax = (a[:, 2:, 1:-1] - a[:, :-2, 1:-1]) / (2 * dx)\n",
    "    # ay = (a[:, 1:-1, 2:] - a[:, 1:-1, :-2]) / (2 * dy)\n",
    "    # uxx = (u[:, 2:, 1:-1] -2*u[:,1:-1,1:-1] +u[:, :-2, 1:-1]) / (dx**2)\n",
    "    # uyy = (u[:, 1:-1, 2:] -2*u[:,1:-1,1:-1] +u[:, 1:-1, :-2]) / (dy**2)\n",
    "\n",
    "    a = a[:, 1:-1, 1:-1]\n",
    "    # u = u[:, 1:-1, 1:-1]\n",
    "    # Du = -(ax*ux + ay*uy + a*uxx + a*uyy)\n",
    "\n",
    "    # inner1 = torch.mean(a*(ux**2 + uy**2), dim=[1,2])\n",
    "    # inner2 = torch.mean(f*u, dim=[1,2])\n",
    "    # return 0.5*inner1 - inner2\n",
    "\n",
    "    aux = a * ux\n",
    "    auy = a * uy\n",
    "    auxx = (aux[:, 2:, 1:-1] - aux[:, :-2, 1:-1]) / (2 * dx)\n",
    "    auyy = (auy[:, 1:-1, 2:] - auy[:, 1:-1, :-2]) / (2 * dy)\n",
    "    Du = - (auxx + auyy)\n",
    "    return Du\n",
    "\n",
    "\n",
    "def darcy_loss(u, a):\n",
    "    batchsize = u.size(0)\n",
    "    size = u.size(1)\n",
    "    u = u.reshape(batchsize, size, size)\n",
    "    a = a.reshape(batchsize, size, size)\n",
    "    lploss = LpLoss(size_average=True)\n",
    "\n",
    "    # index_x = torch.cat([torch.tensor(range(0, size)), (size - 1) * torch.ones(size), torch.tensor(range(size-1, 1, -1)),\n",
    "    #                      torch.zeros(size)], dim=0).long()\n",
    "    # index_y = torch.cat([(size - 1) * torch.ones(size), torch.tensor(range(size-1, 1, -1)), torch.zeros(size),\n",
    "    #                      torch.tensor(range(0, size))], dim=0).long()\n",
    "\n",
    "    # boundary_u = u[:, index_x, index_y]\n",
    "    # truth_u = torch.zeros(boundary_u.shape, device=u.device)\n",
    "    # loss_u = lploss.abs(boundary_u, truth_u)\n",
    "\n",
    "    Du = FDM_Darcy(u, a)\n",
    "    f = torch.ones(Du.shape, device=u.device)\n",
    "    loss_f = lploss.rel(Du, f)\n",
    "\n",
    "    # im = (Du-f)[0].detach().cpu().numpy()\n",
    "    # plt.imshow(im)\n",
    "    # plt.show()\n",
    "\n",
    "    # loss_f = FDM_Darcy(u, a)\n",
    "    # loss_f = torch.mean(loss_f)\n",
    "    return loss_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9401b3-8e10-4397-8d2e-11918f4e7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DarcyDataAndPinnsLoss(nn.Module):\n",
    "    def __init__(self, pinn_loss_weight:float):\n",
    "        super().__init__()\n",
    "        self.L1 = nn.L1Loss()\n",
    "        self.lploss = LpLoss(size_average=True)\n",
    "        self.pinn_loss_weight = pinn_loss_weight\n",
    "\n",
    "    def forward(self, model_pred:torch.Tensor, ground_truth:torch.Tensor):\n",
    "        \"\"\"Loss calculation.\n",
    "            model_pred shape: batch_size x 1 (no time) x X_dim x Y_dim\n",
    "            ground_truth shape: same as model pred\n",
    "        \"\"\"\n",
    "        data_loss = self.L1(model_pred, ground_truth)\n",
    "\n",
    "        batchsize = model_pred.size(0)\n",
    "        size = ground_truth.size(-1)\n",
    "        u = model_pred.reshape(batchsize, size, size)\n",
    "        a = ground_truth.reshape(batchsize, size, size)\n",
    "        Du = FDM_Darcy(u, a)\n",
    "        f = torch.ones(Du.shape, device=u.device)\n",
    "        pinn_loss = self.lploss.rel(Du, f)\n",
    "        \n",
    "        return (1 - self.pinn_loss_weight) * data_loss + self.pinn_loss_weight * pinn_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f1cc08-c231-42f3-8275-bd28fdd37542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, train_loss=0.16677389920703947\n",
      "epoch=1, train_loss=0.16411511552712274\n",
      "epoch=2, train_loss=0.16248389203397054\n",
      "epoch=3, train_loss=0.16238959748593587\n",
      "epoch=4, train_loss=0.16045862885694656\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-8\n",
    "step_size = 15\n",
    "gamma = 0.5\n",
    "# set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=step_size, gamma=gamma\n",
    ")\n",
    "loss = get_loss(\"l1\")\n",
    "\n",
    "data_loss_weight = 0.95\n",
    "pinn_loss_weight = 0.05\n",
    "\n",
    "darcy_pinn_loss = DarcyDataAndPinnsLoss(pinn_loss_weight=0.5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for _step, batch in enumerate(train_dataloader):  \n",
    "        input_batch = batch['x'].to(device)\n",
    "        output_batch = batch['y'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_pred_batch = model(input_batch)\n",
    "\n",
    "        loss_f = darcy_pinn_loss(output_pred_batch, output_batch)\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss_f.item()\n",
    "    train_loss /= len(train_dataloader)\n",
    "    scheduler.step()\n",
    "    print(f\"{epoch=}, {train_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8db6009-8fed-4472-a53d-89edb5cf101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1Loss()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef0c89-85ac-4878-8676-5162942e3e66",
   "metadata": {},
   "source": [
    "# Burgers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cc796f2-6e85-4018-9a6f-606ce9abfba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "data_kwargs = {\n",
    "    'dataset_name': 'burgers_pdebench',\n",
    "    'filter_lim': -1,\n",
    "    'img_size': 1024,\n",
    "    'downsample_dim': -1,\n",
    "    'batch_size':7,\n",
    "    'seed':0,\n",
    "    'initial_steps':10,\n",
    "    'model_name':'FNO1d',\n",
    "    'darcy_forcing_term':1,\n",
    "}\n",
    "\n",
    "train_dataloader, test_loaders = get_data(**data_kwargs)\n",
    "\n",
    "model = get_model(\n",
    "            model_name='FNO1D',\n",
    "            out_channels=1,\n",
    "            in_channels=10,\n",
    "            hidden_channels=32,\n",
    "            max_modes=16,\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24575f33-907a-470d-9277-abae81588953",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 1.0 # viscosity (from dataset)\n",
    "\n",
    "def FDM_Burgers(u, v, D=1):\n",
    "    batchsize = u.size(0)\n",
    "    nt = u.size(1)\n",
    "    nx = u.size(-1)\n",
    "\n",
    "    u = u.reshape(batchsize, nt, nx)\n",
    "    dt = D / (nt-1)\n",
    "    dx = D / (nx)\n",
    "\n",
    "    u_h = torch.fft.fft(u, dim=2)\n",
    "    # Wavenumbers in y-direction\n",
    "    k_max = nx//2\n",
    "    k_x = torch.cat((torch.arange(start=0, end=k_max, step=1, device=u.device),\n",
    "                     torch.arange(start=-k_max, end=0, step=1, device=u.device)), 0).reshape(1,1,nx)\n",
    "    ux_h = 2j *np.pi*k_x*u_h\n",
    "    uxx_h = 2j *np.pi*k_x*ux_h\n",
    "    ux = torch.fft.irfft(ux_h[:, :, :k_max+1], dim=2, n=nx)\n",
    "    uxx = torch.fft.irfft(uxx_h[:, :, :k_max+1], dim=2, n=nx)\n",
    "    ut = (u[:, 2:, :] - u[:, :-2, :]) / (2 * dt)\n",
    "    Du = ut + (ux*u - v*uxx)[:,1:-1,:]\n",
    "    return Du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72cff4be-8941-4657-ab31-c1c16a09d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_steps = 10\n",
    "for _step, batch in enumerate(train_dataloader):  \n",
    "    input_batch = batch['x'].to(device).squeeze()\n",
    "    output_batch = batch['y'].to(device).squeeze()\n",
    "    img_size = input_batch.shape[-1]\n",
    "    batch_size = input_batch.shape[0]\n",
    "    loss_f = 0\n",
    "    t_train = output_batch.shape[1]  # number of time steps\n",
    "    shape = (batch_size, -1)\n",
    "    for _dim in range(model.n_dim):\n",
    "        shape += (img_size,)\n",
    "\n",
    "    preds = []\n",
    "    for t in range(initial_steps, t_train):\n",
    "        # Extract target at current time step\n",
    "        # squeeze out time dim\n",
    "        output_at_time_step = output_batch[:, t : t + 1, ...].squeeze(dim=1)\n",
    "\n",
    "        # Model run\n",
    "        model_input = torch.reshape(input_batch, shape)\n",
    "        output_pred_batch = model(model_input)\n",
    "        preds.append(output_pred_batch)\n",
    "\n",
    "    full_model_preds = torch.stack(preds, dim=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53681bf9-e7cc-4d3a-aaf1-882d5a20f825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 91, 1, 1024])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(preds, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1110d5af-bb18-4854-b2e8-0fc90bf2d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10, 1024])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "450d04af-dbe9-4ec2-af3e-d8e50f9ba9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 89, 1024])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pred_batch = input_batch # temp just to get correct shape\n",
    "\n",
    "FDM_Burgers(full_model_preds, v).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aef5cf25-c62f-411b-887b-9c36f83c9bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 10, 1024])\n",
      "torch.Size([7, 10, 1024])\n"
     ]
    }
   ],
   "source": [
    "u = input_batch\n",
    "batchsize = u.size(0)\n",
    "nt = u.size(1)\n",
    "nx = u.size(2)\n",
    "print(u.shape)\n",
    "\n",
    "u = u.reshape(batchsize, nt, nx)\n",
    "print(u.shape)\n",
    "# lploss = LpLoss(size_average=True)\n",
    "\n",
    "index_t = torch.zeros(nx,).long()\n",
    "index_x = torch.tensor(range(nx)).long()\n",
    "boundary_u = u[:, index_t, index_x]\n",
    "#loss_u = F.mse_loss(boundary_u, u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85cc7581-d0e5-45ec-b926-f50fcc97d195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548df6ec-df6b-42ad-b4bf-f3cf7ae00295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PINO_loss(u, u0, v):\n",
    "    batchsize = u.size(0)\n",
    "    nt = u.size(1)\n",
    "    nx = u.size(2)\n",
    "\n",
    "    u = u.reshape(batchsize, nt, nx)\n",
    "    # lploss = LpLoss(size_average=True)\n",
    "\n",
    "    index_t = torch.zeros(nx,).long()\n",
    "    index_x = torch.tensor(range(nx)).long()\n",
    "    boundary_u = u[:, index_t, index_x]\n",
    "    loss_u = F.mse_loss(boundary_u, u0)\n",
    "\n",
    "    Du = FDM_Burgers(u, v)[:, :, :]\n",
    "    f = torch.zeros(Du.shape, device=u.device)\n",
    "    loss_f = F.mse_loss(Du, f)\n",
    "\n",
    "    return loss_u, loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42df3120-32a6-432c-9d24-1eb0c7bde4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 10, 1, 1024])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12244187-1c2f-4861-b52f-94c3513c4969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "loss = nn.L1Loss()\n",
    "\n",
    "loss(full_model_preds, full_model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a3fdf65-31eb-4d0c-a7c5-27ebb35689fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 91, 1, 1024])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_preds.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "operator_alias",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
