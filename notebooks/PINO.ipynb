{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd21fb0-1b84-4c63-8668-5104643fc8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator_aliasing.data.utils import get_data\n",
    "from operator_aliasing.models.utils import get_model\n",
    "from operator_aliasing.train.utils import get_loss\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51eb9af-2432-42a2-82d1-60ed8cec836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test db for resolution 16 with 100 samples \n",
      "Loading test db for resolution 16 with 100 samples \n"
     ]
    }
   ],
   "source": [
    "# Get Data\n",
    "data_kwargs = {\n",
    "    'dataset_name': 'darcy',\n",
    "    'filter_lim': 3,\n",
    "    'img_size': 16,\n",
    "    'downsample_dim': -1,\n",
    "    'train': True,\n",
    "    'batch_size':16,\n",
    "    'seed':0,\n",
    "}\n",
    "\n",
    "train_dataloader, test_loaders = get_data(**data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0744d812-6977-43f7-835a-364c4a7783f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "            model_name='FNO2D',\n",
    "            out_channels=1,\n",
    "            in_channels=1,\n",
    "            hidden_channels=32,\n",
    "            max_modes=16,\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e90f4a67-56bd-45c8-8d7b-11671d68a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    '''\n",
    "    loss function with rel/abs Lp loss\n",
    "    '''\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "# PINNs Loss\n",
    "\n",
    "# u = model pred\n",
    "# a = label\n",
    "def FDM_Darcy(u, a, D=1):\n",
    "    batchsize = u.size(0)\n",
    "    size = u.size(1)\n",
    "    u = u.reshape(batchsize, size, size)\n",
    "    a = a.reshape(batchsize, size, size)\n",
    "    dx = D / (size - 1)\n",
    "    dy = dx\n",
    "\n",
    "    # ux: (batch, size-2, size-2)\n",
    "    ux = (u[:, 2:, 1:-1] - u[:, :-2, 1:-1]) / (2 * dx)\n",
    "    uy = (u[:, 1:-1, 2:] - u[:, 1:-1, :-2]) / (2 * dy)\n",
    "\n",
    "    # ax = (a[:, 2:, 1:-1] - a[:, :-2, 1:-1]) / (2 * dx)\n",
    "    # ay = (a[:, 1:-1, 2:] - a[:, 1:-1, :-2]) / (2 * dy)\n",
    "    # uxx = (u[:, 2:, 1:-1] -2*u[:,1:-1,1:-1] +u[:, :-2, 1:-1]) / (dx**2)\n",
    "    # uyy = (u[:, 1:-1, 2:] -2*u[:,1:-1,1:-1] +u[:, 1:-1, :-2]) / (dy**2)\n",
    "\n",
    "    a = a[:, 1:-1, 1:-1]\n",
    "    # u = u[:, 1:-1, 1:-1]\n",
    "    # Du = -(ax*ux + ay*uy + a*uxx + a*uyy)\n",
    "\n",
    "    # inner1 = torch.mean(a*(ux**2 + uy**2), dim=[1,2])\n",
    "    # inner2 = torch.mean(f*u, dim=[1,2])\n",
    "    # return 0.5*inner1 - inner2\n",
    "\n",
    "    aux = a * ux\n",
    "    auy = a * uy\n",
    "    auxx = (aux[:, 2:, 1:-1] - aux[:, :-2, 1:-1]) / (2 * dx)\n",
    "    auyy = (auy[:, 1:-1, 2:] - auy[:, 1:-1, :-2]) / (2 * dy)\n",
    "    Du = - (auxx + auyy)\n",
    "    return Du\n",
    "\n",
    "\n",
    "def darcy_loss(u, a):\n",
    "    batchsize = u.size(0)\n",
    "    size = u.size(1)\n",
    "    u = u.reshape(batchsize, size, size)\n",
    "    a = a.reshape(batchsize, size, size)\n",
    "    lploss = LpLoss(size_average=True)\n",
    "\n",
    "    # index_x = torch.cat([torch.tensor(range(0, size)), (size - 1) * torch.ones(size), torch.tensor(range(size-1, 1, -1)),\n",
    "    #                      torch.zeros(size)], dim=0).long()\n",
    "    # index_y = torch.cat([(size - 1) * torch.ones(size), torch.tensor(range(size-1, 1, -1)), torch.zeros(size),\n",
    "    #                      torch.tensor(range(0, size))], dim=0).long()\n",
    "\n",
    "    # boundary_u = u[:, index_x, index_y]\n",
    "    # truth_u = torch.zeros(boundary_u.shape, device=u.device)\n",
    "    # loss_u = lploss.abs(boundary_u, truth_u)\n",
    "\n",
    "    Du = FDM_Darcy(u, a)\n",
    "    f = torch.ones(Du.shape, device=u.device)\n",
    "    loss_f = lploss.rel(Du, f)\n",
    "\n",
    "    # im = (Du-f)[0].detach().cpu().numpy()\n",
    "    # plt.imshow(im)\n",
    "    # plt.show()\n",
    "\n",
    "    # loss_f = FDM_Darcy(u, a)\n",
    "    # loss_f = torch.mean(loss_f)\n",
    "    return loss_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f1cc08-c231-42f3-8275-bd28fdd37542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, train_loss=0.1665982005615083\n",
      "epoch=1, train_loss=0.1642174647440986\n",
      "epoch=2, train_loss=0.16323051920958928\n",
      "epoch=3, train_loss=0.16174429134717064\n",
      "epoch=4, train_loss=0.15996588198911577\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-8\n",
    "step_size = 15\n",
    "gamma = 0.5\n",
    "# set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=step_size, gamma=gamma\n",
    ")\n",
    "loss = get_loss(\"l1\")\n",
    "\n",
    "data_loss_weight = 0.95\n",
    "pinn_loss_weight = 0.05\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    for _step, batch in enumerate(train_dataloader):  \n",
    "        input_batch = batch['x'].to(device)\n",
    "        output_batch = batch['y'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_pred_batch = model(input_batch)\n",
    "        data_loss = loss(output_pred_batch, output_batch)\n",
    "\n",
    "        pinn_loss = darcy_loss(output_pred_batch.squeeze(), output_batch.squeeze())\n",
    "        #loss_f = data_loss\n",
    "        loss_f = data_loss_weight * data_loss + pinn_loss_weight * pinn_loss\n",
    "        loss_f.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss_f.item()\n",
    "    train_loss /= len(train_dataloader)\n",
    "    scheduler.step()\n",
    "    print(f\"{epoch=}, {train_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db6009-8fed-4472-a53d-89edb5cf101e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "operator_alias",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
