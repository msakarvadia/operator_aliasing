<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Studying and correcting aliasing in machine-learned operators.">
  <meta property="og:title" content="The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators"/>
  <meta property="og:description" content="The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators"/>
  <meta property="og:url" content="https://mansisak.com/operator_aliasing/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/aliasing_overview.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators">
  <meta name="twitter:description" content="The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/aliasing_overview.png">
  <meta name="twitter:card" content="The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="machine-learning, PDE, signal-processing, partial-differential-equations, multi-resoution, aliasing">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://mansisak.com/" target="_blank">Mansi Sakarvadia</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://khegazy.github.io/" target="_blank">Kareem Hegazy</a><sup>5,6</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.ki.uni-stuttgart.de/de/institut/team/Totounferoush-00002/" target="_blank">Amin Totounferoush</a><sup>3</sup>,
                  </span>
                <span class="author-block">
                  <a href="https://kylechard.com/" target="_blank">Kyle Chard</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://sites.google.com/site/yangyaoqingcmu/home" target="_blank">Yaoqing Yang</a><sup>4</sup>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=VGoSakQAAAAJ&hl=en" target="_blank">Ian Foster</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://www.stat.berkeley.edu/~mmahoney/" target="_blank">Michael W. Mahoney</a><sup>2,5,6</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <sup>1</sup>University of Chicago,
                  <sup>2</sup>Lawrence Berkeley National Laboratory,
                  <sup>3</sup>University of Stuttgart,
                  <sup>4</sup>Dartmouth College,
                  <sup>5</sup>International Computer Science Institute,
                  <sup>6</sup>University of California, Berkeley,
                </span>
              </div>
            

                  <div class="column has-text-centered">


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/msakarvadia/operator_aliasing" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  <!-- Overview fig -->
<section class="hero teaser">
			<div class="container is-max-desktop">
				<!-- Your image here -->
				<img src="static/images/all_methods_aliasing_vis.png" alt="Evaluating multi-resolution inference using different training strategies."/>
				<h2 class="subtitle has-text-centered">
          Assessing multi-resolution inference. Column 1: Expected prediction for Darcy flow at varying resolutions. Columns 2-6: Sample prediction for Darcy flow at varying test resolutions. Column 7: Average mean squared error test loss at each resolution (lower is better). Zero-shot methods: CNO, FNO, Physics Informed and CROP are all zero-shot methods, meaning the model was trained at a specific resolution (16) and evaluated at resolutions 16, 32, 64, 128. Data-driven method: Multi-resolution training (proposed); notice that multi-resolution training consistently outperforms zero-shot methods.
				</h2>
				</img>
			</div>
</section> 

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            A core challenge in scientific machine learning, and scientific computing more generally, is modeling continuous phenomena which (in practice) are represented discretely. Machine-learned operators (MLOs) have been introduced as a means to achieve this modeling goal, as this class of architecture can perform inference at arbitrary resolution. In this work, we evaluate whether this architectural innovation is sufficient to perform “zero-shot super-resolution,” namely to enable a model to serve inference on higher-resolution data than that on which it was originally trained. We comprehensively evaluate both zero-shot sub-resolution and super-resolution (i.e., multi-resolution) inference in MLOs. We decouple multi-resolution inference into two key behaviors: 1) extrapolation to varying frequency information; and 2) interpolating across varying resolutions. We empirically demonstrate that MLOs fail to do both of these tasks in a zero-shot manner. Consequently, we find MLOs are not able to perform accurate inference at resolutions different from those on which they were trained, and instead they are brittle and susceptible to aliasing. To address these failure modes, we propose a simple, computationally-efficient, and data-driven multi-resolution training protocol that overcomes aliasing and that provides robust multi-resolution generalization.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!--Paper Discussion-->
<section class="section">
	<div class="container is-max-desktop">	
	
	<h2 class="title is-3">What are Machine Learned Operators?</h2>
	<div class="content has-text-justified">
		<p>
		Modeling physical systems governed by partial differential equations (PDEs) is critical to many computational science workflows.
		Central to this problem formulation is that <em>continuous</em> physical systems must be sampled and, therefore, modeled <em>discretely</em>.
		For discrete models to be useful in representing phenomena of different scales, scientists require the ability to use it at different resolutions accurately.
For example, when modeling fluid flow, scientists often use adaptive mesh refinement, a technique that increases simulation resolution in areas that require high accuracy (e.g., regions
of turbulence), and coarsens the resolution in less critical regions.
		<br><br>
		Traditionally, these discrete models are numerical methods which, by design, can be employed at arbitrary discretization. 
		However, numerical methods are computationally expensive.
		Alternatively, <b>machine-learned operators (MLOs)</b>, a class of data-driven machine learning (ML) models which parameterize the solution operator to families of PDEs, have been proposed. 
		Although querying MLOs at arbitrary discretization is computationally inexpensive, it is not obvious that this can be done accurately.
		<br><br>
		In this work we systematically show that the current manner in which MLOs are trained does not enable them to do accurate multi-resolution inference. 
			We then propose a data-driven solution, namely, multi-resolution training, which elicits the desired behavior.
		<br><br>
		<img src="static/images/topo_aware_v_unaware.png" alt="Topology Aware vs. Unaware Aggregation."/></img>
		</p>
	</div>
		
	<h2 class="title is-3">Challenge: Discretely Modeling Continuous Systems</h2>
	<div class="content has-text-justified">
		<p>
		
			
		The fundamental challenge in discretely representing continuous systems lies in the choice of sampling rate. 
		The Whittaker–Nyquist–Shannon sampling theorem established that, given a sampling rate r, the largest resolved frequency is r/2. 
		Thus, ML models will be trained on discrete representations, where only some of the frequencies are fully resolved. 
		Resolving higher-order frequencies greater than r/2, consequently, becomes an out-of-distribution task. 
		<b>Aligning these discrete models’ predictions with the underlying continuous system is a non-trivial open problem.</b>
		<br><br>
		Within an ML context, when inferring at different discretizations of a given signal, <em>aliasing</em> can manifest as the divergence between the energy spectrum of the model prediction and the expected output.
		Aliasing indicates a model’s failure to fit the underlying continuous system.

		
			
		In the figure below we represent the true signal via the dashed blue line and the representation of the true signal that we actually measure via the dotted red line.
		Notice that the rate at which I collect measurements of the true signal impacts the type of signal we actually measure.
		<b>Original:</b> Signal is sampled at a rate greater than its <em>Nyquist</em> frequency. 
		<b>Interpolation:</b> Adapting to new sampling rates of a given signal. 
		<b>Extrapolation:</b> Adapting to new frequency information under constant sampling rate. 
		<b>Super-Resolution:</b> Sampling a system at a higher rate, which enables the capture of higher frequency information (interpolation and extrapolation). 
		<b>Aliasing:</b> High-frequency information is misrepresented as a low-frequency information due to insufficient sampling.
		<br><br>
		<img src="static/images/signal_process_overview_w_super_res.png" alt="Signal Processing Overview."/></img>
		<br><br>

		
		</p>
	</div>
	
	
	
	<h2 class="title is-3">Breaking Down Multi-Resolution Inference</h2>
	<div class="content has-text-justified">
		<p>
		We define multi-resolution inference as the ability to do inference at multiple resolutions (e.g., sub-resolution and super-resolution). 
		The <em>zero-shot</em> multi-resolution task employs an ML model, which is trained on data with some resolution, and then tested on data with a different resolution. 
		Zero-shot multi-resolution inference raises two important questions with respect to the generalization abilities of trained models:
		<ol>
		  <li><b>Resolution Interpolation.</b></li> How do models behave when the frequency information in the data remains fixed, but its sampling rate changes from training to inference? Can the model interpolate the fully-resolved signal to varying resolutions?
		  <li><b>Information Extrapolation.</b></li> How do models behave when the resolution remains fixed, but the number of fully resolved frequency components changes from training to inference? For super-resolution, this means can the model extrapolate beyond the frequencies in its training data and model higher frequency information?
		</ol>
		<br><br>
		<img src="static/images/topo_aware_v_unaware.png" alt="Topology Aware vs. Unaware Aggregation."/></img>
		</p>
	</div>

	First, we study <b>resolution interpolation</b>
	
	<h2 class="title is-3">Zero-shot Multi-Resolution or Aliasing?</h2>
	<div class="content has-text-justified">
		<p>
			...
		<br><br>
		<img src="static/images/topo_aware_v_unaware.png" alt="Topology Aware vs. Unaware Aggregation."/></img>
		</p>
	</div>
	
	<h2 class="title is-3">Physical Optimization Constraints</h2>
	<div class="content has-text-justified">
		<p>
		We study if physics-informed optimization constraints are capable of enabling <em>zero-shot multi-resolution inference</em>.
		We optimize each set of model parameters θ with a dual optimization objective L(θ) = (1 − w) ∗ ℓdata(θ) + w ∗ ℓphys(θ), where ℓdata is the original data-driven loss (mean squared error), and where ℓphys is an additional physics-informed loss, which explicitly enforces that the governing PDE is satisfied. 
		First, we find that the data-driven loss always outperforms any training objective that includes a physics constraint.
		<br><br>
		<img src="static/images/pinns_weight_barplot.png" alt="PINN weighting coefficients."/></img>
		<br><br>
		To further illustrate this, we use the smallest non-zero w = 0.1, to train a model at resolution 256 (indicated by *) and compare the physics-informed optimization with solely data-driven optimization. 
		In the following figure, we find that the predicted spectra of data from models optimized with a physics loss generally diverge more substantially across test resolutions than models optimized with only a data loss. 
		Models optimized with physics constraints even fail to accurately fit their training distributions (subfigure (c)), and they fail to generalize to both super- and sub-resolution data (subfigure (a,b,d)). 
		<br><br>
		<img src="static/images/burgers_main_text_summary_pinn_vs_no_pinn_label_spectrums.png" alt="PINN vs Data Driven optimization."/></img>
		<br><br>
		We conclude that physics informed constraints do <em>not</em> reliably enable multi-resolution generalization.
		</p>
	</div>
	
	<h2 class="title is-3">Band-limited Learning</h2>
	<div class="content has-text-justified">
		<p>
		We study two approaches which propose learning band-limited representations of data (i.e., convolutional neural operators (CNO), Cross-Resolution Operator-Learning (CROP)) and assess if they are capable of enabling <em>zero-shot multi-resolution inference</em>.
		We do an experiment where we train CNO and CROP models on resolution 16 data (indicated by *) and evaluate them at resolutions 16, 32, 64, 128. 
		We visualize the average test 2D energy spectra of model predictions and ground truth in the figure below.
		We notice that the predicted spectra from both CROP and CNO diverge from the ground truth after frequency 8.
		<br><br>
		<img src="static/images/all_methods_aliasing_overview_experiment.png" alt="Band-limited learning."/></img>
		<br><br>
		We note more broadly that the design of band-limiting a model’s training data and predictive capacity is counter-intuitive to the goal of multi-resolution inference, in which, a broad range of frequencies must be modeled accurately. 
		<b>Band-limiting a model’s predictive capacity may enable accurate fixed-resolution representations, but it ensures that high-frequency information is not predicted accurately (or at all).</b>
		We conclude that band-limited learning limits a model’s utility for multi-resolution inference.
		</p>
	</div>
	
	<h2 class="title is-3">Proposed: Multi-Resolution Training</h2>
	<div class="content has-text-justified">
		<p>
		<b>We hypothesize that the reason models struggle to do zero-shot multi-resolution inference is because data representing a physical system at varying resolutions is sufficiently out-of-distribution to the model’s fixed-resolution training data.</b>
		To remedy this, we propose a data-driven solution: multi-resolution training (i.e., training on more than one resolution).
		<br><br>
		We do an experiment where we train an FNO on multi-resolution data. The results are shown in the figure below. The bottom row shows the test loss across different resolutions.
		The middle row shows the ratios of training data within each resolution bucket. 
		The top row shows the the average number of pixels in a data sample in the training set; lower number of pixels enables faster data generation and model training.
		<br><br>
		<img src="static/images/darcy_pdebench_0.5_all_less_0_multi_res.png" alt="Multi-Resolution Training."/></img>
		<br><br>
		We first study what happens when you include two resolution in the training data: In subfigures (a-f), we observe for pair-wise training, the test performance for data that corresponds to the two training resolutions is generally better, but we also note that there are not consistent gains for the two non-training resolutions.
		This indicates that models perform best on the data resolutions on which they are trained.
		<br><br>
		To improve multi-resolution capabilities, we investigate the impact of including data from all resolutions. 
		We first assess an equal number of samples across resolutions. 
		In subfigure (g), the test performance across all resolutions improves, which confirms that multi-resolution training benefits multi-resolution inference. 
		Next, we ask: <em>Can we improve the computationally efficiency of multi-resolution training?</em>
		To do this, the training dataset must be composed of primarily low resolution data, as it is both the cheapest to generate and the cheapest to train over. We compose two additional multi-resolution datasets and observe in subfigures (h, i) that models remain competitive across test resolutions, even as we decrease the amount of high-resolution data. 
		</p>
	</div>
	
	<h2 class="title is-3">Conclusion</h2>
		<div class="content has-text-justified">
			<p>
			For MLOs to be as versatile as numerical methods-based approaches for modeling PDEs, they must be able to perform accurate multi-resolution inference. To better understand an MLO’s abilities, we break down the task of multi-resolution inference by assessing a trained model’s ability both to extrapolate to higher/lower frequency information in data and to interpolate across varying data resolutions. We find that models trained on low resolution data and used for inference on high-resolution data can neither extrapolate nor interpolate; and, more generally, they fail to achieve accurate multi-resolution inference. Changing the resolution of data at inference time is akin to out-of-distribution inference: models have not learned how to generalize in such settings. We document that models used in a zero-shot multi-resolution setting are prone to aliasing. We study the utility of two existing solutions–physics-informed constrains and learning band-limited learning–and find that neither enable accurate multi-resolution inference.
			<br><br>
			Based on these results, we introduce a simple, intuitive, and principled approach to enable accurate multi-resolution inference: multi-resolution training. We show that models perform best at resolutions on which they have been trained; and we demonstrate that one can computationally efficiently achieve the benefits of multi-resolution training via datasets composed with mostly low-resolution data and small amounts of high-resolution data. This enables accurate multi-resolution learning, with the added benefit of low data-generation and model training cost. A promising future direction remains the automated selection of multi-resolution training data using strategies like active learning.
			<br><br>
			Further details about all experiments and figures discussed in this blog can be found in the main paper. If there are any questions feel free to email the first author for clarification.
			</p>
		</div>
	</div>

</section>
<!--End Paper Discussion-->
	
<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
            <pre><code>
@article{sakarvadia2025false,
      title={The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators}, 
      author={Mansi Sakarvadia and Kareem Hegazy and Amin Totounferoush and Kyle Chard and Yaoqing Yang and Ian Foster and Michael W. Mahoney},
      year={2025},
      eprint={...},
      url={...}, 
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
